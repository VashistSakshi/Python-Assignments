{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**: Difference between K-Means and Hierarchical Clustering (with use cases)       \n",
        "**Answer**: **K-Means Clustering**\n",
        "\n",
        "- Partitions data into a fixed number (K) of clusters\n",
        "\n",
        "- Uses centroids and minimizes within-cluster variance\n",
        "\n",
        "- Fast and scalable for large datasets\n",
        "\n",
        "- Sensitive to initial centroids and outliers\n",
        "\n",
        "**Use case**:\n",
        "Customer segmentation in large retail datasets where the number of segments is roughly known in advance.             \n",
        "**Hierarchical Clustering**\n",
        "\n",
        "- Builds clusters step by step (bottom-up or top-down)\n",
        "\n",
        "- Does not require predefining number of clusters\n",
        "\n",
        "- Produces a dendrogram showing cluster hierarchy\n",
        "\n",
        "- Computationally expensive for large datasets\n",
        "\n",
        "**Use case**:\n",
        "Genetic or document similarity analysis where understanding relationships between clusters is important."
      ],
      "metadata": {
        "id": "pklX1e7wvCEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**: Purpose of the Silhouette Score             \n",
        "\n",
        "**Answer**: The Silhouette Score measures how well a data point fits within its assigned cluster compared to other clusters.\n",
        "\n",
        "- Value ranges from −1 to +1\n",
        "\n",
        "- Higher value → better clustering\n",
        "\n",
        "- Considers both:\n",
        "\n",
        "**Cohesion** (within-cluster distance)\n",
        "\n",
        "**Separation** (between-cluster distance)\n",
        "\n",
        "Why it matters:   \n",
        "Helps evaluate clustering quality without ground truth labels."
      ],
      "metadata": {
        "id": "3p2ykl2SvmCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**: Core parameters of DBSCAN and their influence\n",
        "\n",
        "\n",
        "**Answer**: **eps (epsilon)**              \n",
        "- Radius around a data point\n",
        "\n",
        "- Controls neighborhood size\n",
        "\n",
        "- Too small → many points marked as noise\n",
        "\n",
        "- Too large → clusters merge\n",
        "\n",
        "**min_samples**\n",
        "\n",
        "- Minimum number of points required to form a dense region\n",
        "\n",
        "- Higher value → stricter clusters\n",
        "\n",
        "- Lower value → more clusters, more noise sensitivity\n",
        "\n",
        " Together, they define density, not shape or size."
      ],
      "metadata": {
        "id": "CbYGvd5Fv7Ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**: Why feature scaling is important in clustering\n",
        "\n",
        "**Answer**:                 \n",
        "- Distance-based algorithms (K-Means, DBSCAN) rely on Euclidean distance\n",
        "\n",
        "- Features with larger ranges dominate distance calculations\n",
        "\n",
        "- Scaling ensures equal contribution from all features\n",
        "\n",
        "Without scaling:\n",
        "\n",
        "- Clusters become biased\n",
        "\n",
        "- DBSCAN density estimation fails\n",
        "\n",
        "- K-Means centroids shift incorrectly"
      ],
      "metadata": {
        "id": "-xJI4XmywTF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**: Elbow Method in K-Means\n",
        "\n",
        "**Answer**: The Elbow Method plots:\n",
        "\n",
        "- Number of clusters (K) vs\n",
        "\n",
        "- Inertia (within-cluster sum of squares)\n",
        "\n",
        "As K increases:\n",
        "\n",
        "- Inertia decreases\n",
        "\n",
        "- At some point, improvement slows → elbow point\n",
        "\n",
        "This elbow indicates the optimal number of clusters."
      ],
      "metadata": {
        "id": "3U4Nbwv5wj4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**: K-Means on make_blobs data (with visualization)"
      ],
      "metadata": {
        "id": "BYG0VsGVwzIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, _ = make_blobs(n_samples=300, centers=4, random_state=42)\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0],\n",
        "            kmeans.cluster_centers_[:, 1],\n",
        "            marker='X', s=200)\n",
        "plt.title(\"K-Means Clustering on make_blobs\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V_mi1hn8w2WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7**: DBSCAN on Wine dataset (with scaling)"
      ],
      "metadata": {
        "id": "Cx7zpkz2w8Te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "\n",
        "X, _ = load_wine(return_X_y=True)\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "dbscan = DBSCAN(eps=1.5, min_samples=5)\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "print(\"Number of clusters (excluding noise):\", n_clusters)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c-yz6iiyw_Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8**: DBSCAN on make_moons data (outliers highlighted)"
      ],
      "metadata": {
        "id": "6R_xDz5DxDlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, _ = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
        "\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
        "labels = dbscan.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
        "plt.title(\"DBSCAN on make_moons (Noise = -1)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3LPqHXofxHgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9**: PCA + Agglomerative Clustering on Wine dataset"
      ],
      "metadata": {
        "id": "d6IcTpDExL7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "X, _ = load_wine(return_X_y=True)\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "agg = AgglomerativeClustering(n_clusters=3)\n",
        "labels = agg.fit_predict(X_pca)\n",
        "\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels)\n",
        "plt.title(\"Agglomerative Clustering on PCA-reduced Wine Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m_Dfqd69xOME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10**: Real-world e-commerce clustering workflow        \n",
        "**Answer**:              \n",
        "**Step 1**: Algorithm choice\n",
        "\n",
        "K-Means for large-scale customer segmentation\n",
        "\n",
        "DBSCAN for detecting niche or anomalous customers\n",
        "\n",
        "Hierarchical clustering for exploratory analysis\n",
        "\n",
        "**Step 2**: Data preprocessing\n",
        "\n",
        "Handle missing values (mean / median / mode)\n",
        "\n",
        "Encode categorical variables\n",
        "\n",
        "Apply StandardScaler\n",
        "\n",
        "Remove extreme outliers            \n",
        "**Step 3**: Choosing number of clusters\n",
        "\n",
        "Elbow Method\n",
        "\n",
        "Silhouette Score\n",
        "\n",
        "Business interpretability (marketing relevance)\n",
        "\n",
        "**Step 4**: Business benefits\n",
        "\n",
        "Personalized promotions\n",
        "\n",
        "Improved customer retention\n",
        "\n",
        "Better product recommendations\n",
        "\n",
        "Higher conversion rates"
      ],
      "metadata": {
        "id": "hw9-UppSxQ5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('kmeans', KMeans(n_clusters=5, random_state=42))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_scaled)\n",
        "print(\"Customer clustering completed\")\n"
      ],
      "metadata": {
        "id": "ZETm8YevxUxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}