{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**: What is Simple Linear Regression?\n",
        "\n",
        "Simple Linear Regression (SLR) is a supervised machine learning and statistical technique used to model and analyze the relationship between one independent variable (X) and one dependent variable (Y).\n",
        "It assumes that the relationship between X and Y can be represented using a straight line.\n",
        "\n",
        "Mathematical Representation        \n",
        "ð‘Œ=ð›½0+ð›½1ð‘‹+ðœ€Y=Î²0+Î²1X+Îµ\n",
        "\n",
        "Where:\n",
        "\n",
        "ð‘Œ\n",
        "Y = dependent variable (target)\n",
        "\n",
        "ð‘‹\n",
        "X = independent variable (predictor)\n",
        "\n",
        "ð›½\n",
        "0\n",
        "Î²\n",
        "0= intercept (value of Y when X = 0)\n",
        "\n",
        "ð›½\n",
        "1\n",
        "Î²\n",
        "1= slope (change in Y for one-unit change in X)\n",
        "\n",
        "ðœ€\n",
        "Îµ = random error term\n",
        "\n",
        "**Purpose of Simple Linear Regression**         \n",
        "   1. To predict the value of Y based on X\n",
        "   2. To quantify the strength and direction of the relationship\n",
        "   3. To understand cause-and-effect relationships\n",
        "\n",
        "\n",
        "**Example**         \n",
        "Predicting:\n",
        "\n",
        "   -Salary based on years of experience\n",
        "\n",
        "  -Sales based on advertising spend\n",
        "\n",
        "Advantages:\n",
        "\n",
        "   1. Easy to understand and interpret\n",
        "\n",
        "2. Computationally efficient\n",
        "\n",
        "3. Useful for exploratory analysis\n",
        "\n",
        "Limitations:\n",
        "\n",
        "1. Cannot model complex relationships\n",
        "\n",
        "2. Sensitive to outliers\n",
        "\n",
        "3. Assumes linearity\n",
        "                                           \n",
        "**Question 2:** Key Assumptions of Simple Linear Regression\n",
        "\n",
        "For Simple Linear Regression to give valid results, the following assumptions must be satisfied:\n",
        "\n",
        "1. Linearity\n",
        "\n",
        "There must be a linear relationship between X and Y.\n",
        "If the relationship is curved, SLR will give poor predictions.\n",
        "\n",
        "2. Independence of Errors\n",
        "\n",
        "Observations must be independent of each other.\n",
        "This is especially important in time-series data.\n",
        "\n",
        "3. Homoscedasticity\n",
        "\n",
        "The variance of residuals should be constant across all values of X.\n",
        "If variance changes â†’ heteroscedasticity occurs.\n",
        "\n",
        "4. Normality of Errors\n",
        "\n",
        "Residuals should follow a normal distribution for valid confidence intervals and hypothesis testing.\n",
        "\n",
        "5. No Outliers with High Influence\n",
        "\n",
        "Extreme values can significantly affect the slope and intercept.\n",
        "\n",
        "Why Assumptions Matter:\n",
        "\n",
        "Violating these assumptions leads to:\n",
        "\n",
        "- Biased estimates\n",
        "\n",
        "- Invalid statistical tests\n",
        "\n",
        "- Poor predictive performance\n",
        "\n",
        "**Question 3**: What is Heteroscedasticity and Why Is It Important?\n",
        "Definition\n",
        "\n",
        "Heteroscedasticity occurs when the spread (variance) of residuals is not constant across levels of the independent variable.\n",
        "\n",
        "**Types**\n",
        "\n",
        "- Increasing variance (fan-shaped)\n",
        "\n",
        "- Decreasing variance\n",
        "\n",
        "- Random pattern\n",
        "\n",
        "Why It Is a Problem:\n",
        "\n",
        "- Regression coefficients remain unbiased but become inefficient\n",
        "\n",
        "- Standard errors are incorrect.\n",
        "\n",
        "- Confidence intervals and p-values become misleading.\n",
        "\n",
        "- Detection Methods.\n",
        "\n",
        "- Residual vs fitted value plot.\n",
        "\n",
        "- Breusch-Pagan test.\n",
        "\n",
        "- Whiteâ€™s test.\n",
        "\n",
        "How to Fix It\n",
        "\n",
        "- Log or square-root transformation\n",
        "\n",
        "- Weighted Least Squares\n",
        "\n",
        "- Robust standard errors\n",
        "\n",
        "**Question 4**: What is Multiple Linear Regression?\n",
        "\n",
        "Multiple Linear Regression (MLR) extends simple linear regression by allowing two or more independent variables to predict a single dependent variable.\n",
        "\n",
        "Equation\n",
        "Y=Î²0â€‹+Î²1â€‹X1â€‹+Î²2â€‹X2â€‹+â‹¯+Î²nâ€‹Xnâ€‹+Îµ\tâ€‹\n",
        "\n",
        "Use Cases:\n",
        "\n",
        "- House price prediction (area, rooms, location)\n",
        "\n",
        "- Sales forecasting (price, promotions, seasonality)\n",
        "\n",
        "- Medical diagnosis (age, BMI, blood pressure)\n",
        "\n",
        "Key Benefits :\n",
        "\n",
        "- Captures the effect of multiple factors\n",
        "\n",
        "- More realistic modeling\n",
        "\n",
        "- Better predictive power\n",
        "\n",
        "Key Challenge:\n",
        "\n",
        "- Multicollinearity between predictors\n",
        "\n",
        "**Question 5**: What is Polynomial Regression?\n",
        "\n",
        "Polynomial Regression models non-linear relationships by transforming the independent variable into polynomial terms while still using linear regression techniques.\n",
        "\n",
        "Example (2nd Degree)              \n",
        "Y=Î²0â€‹+Î²1â€‹X+Î²2â€‹X2+Îµ           \n",
        "Applications\n",
        "\n",
        "- Growth curves\n",
        "\n",
        "- Temperature trends\n",
        "\n",
        "- Economics and finance modeling\n",
        "\n",
        "**Question 6**: Simple Linear Regression â€“ Python Implementation\n"
      ],
      "metadata": {
        "id": "jf9RXu9WZDw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2.1, 4.3, 6.1, 7.9, 10.2])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "Y_pred = model.predict(X)\n",
        "\n",
        "plt.scatter(X, Y)\n",
        "plt.plot(X, Y_pred)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Simple Linear Regression\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L94kwQCzdTeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Multiple Linear Regression & Multicollinearity (VIF)\n",
        "Multicollinearity\n",
        "\n",
        "Occurs when independent variables are highly correlated.\n",
        "\n",
        "Why It Is Dangerous\n",
        "\n",
        "Unstable coefficients\n",
        "\n",
        "Difficult interpretation\n",
        "\n",
        "Reduced model reliability\n",
        "\n",
        "Variance Inflation Factor (VIF)\n",
        "VIF=\n",
        "1âˆ’R\n",
        "2\n",
        "1\n",
        "\tâ€‹\n",
        "\tâ€‹\n",
        "\n",
        "Interpretation\n",
        "\n",
        "VIF = 1 â†’ No multicollinearity\n",
        "\n",
        "VIF > 5 â†’ Moderate\n",
        "\n",
        "VIF > 10 â†’ Severe"
      ],
      "metadata": {
        "id": "pBHVO2tfdjZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    \"Area\": [1200, 1500, 1800, 2000],\n",
        "    \"Rooms\": [2, 3, 3, 4],\n",
        "    \"Price\": [250000, 300000, 320000, 370000]\n",
        "})\n",
        "\n",
        "X = data[[\"Area\", \"Rooms\"]]\n",
        "y = data[\"Price\"]\n",
        "\n",
        "# Fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# VIF calculation\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Feature\"] = X.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "              for i in range(X.shape[1])]\n",
        "\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "inE1tGXddwtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Polynomial Regression (2nd Degree)"
      ],
      "metadata": {
        "id": "SoiSy6AreBqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2.2, 4.8, 7.5, 11.2, 14.7])\n",
        "\n",
        "# Polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, Y)\n",
        "\n",
        "# Curve\n",
        "X_line = np.linspace(1, 5, 100).reshape(-1, 1)\n",
        "X_line_poly = poly.transform(X_line)\n",
        "Y_line = model.predict(X_line_poly)\n",
        "\n",
        "# Plot\n",
        "plt.scatter(X, Y)\n",
        "plt.plot(X_line, Y_line)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Polynomial Regression (Degree 2)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wZ8s5-_VeGgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Residual Plot (Heteroscedasticity Check)"
      ],
      "metadata": {
        "id": "N2xKmIJIeIr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Data\n",
        "X = np.array([10, 20, 30, 40, 50]).reshape(-1, 1)\n",
        "Y = np.array([15, 35, 40, 50, 65])\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Predictions and residuals\n",
        "Y_pred = model.predict(X)\n",
        "residuals = Y - Y_pred\n",
        "\n",
        "# Residual plot\n",
        "plt.scatter(X, residuals)\n",
        "plt.axhline(0)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eDA9GGkpeKJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Handling Heteroscedasticity & Multicollinearity (Code)"
      ],
      "metadata": {
        "id": "nAzfPx3CeMLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    \"Area\": [1200, 1500, 1800, 2000],\n",
        "    \"Rooms\": [2, 3, 3, 4],\n",
        "    \"Price\": [250000, 300000, 320000, 370000]\n",
        "})\n",
        "\n",
        "# Log transformation to handle heteroscedasticity\n",
        "data[\"LogPrice\"] = np.log(data[\"Price\"])\n",
        "\n",
        "X = data[[\"Area\", \"Rooms\"]]\n",
        "X = sm.add_constant(X)\n",
        "y = data[\"LogPrice\"]\n",
        "\n",
        "# Robust regression\n",
        "model = sm.OLS(y, X).fit(cov_type=\"HC3\")\n",
        "print(model.summary())\n",
        "\n",
        "# VIF check\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Feature\"] = X.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "              for i in range(X.shape[1])]\n",
        "\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "c6md4xDqeNa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}